{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Galaxy Zoo Dataset\n",
    "\n",
    "Galaxy Zoo is a citizen science project for the morphological classification of galaxies from their RGB image. They provide their results as part of a kaggle competition at [www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge/](https://www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge/)\n",
    "Here we download this data and perform a vanilla classification task.\n",
    "\n",
    "In order to load the data directly from kaggle to the colab notebook, you have to be registered in kaggle and first download an API file from their homepage: go to [www.kaggle.com](https://www.kaggle.com), navigate to you profile info (click your picture in top right and then click \"Your Profile\"). Click \"Account\", scroll down to \"API\" and click \"Generate new API token\". This will download a \"kaggle.json\" file. \n",
    "Start the notebook in colab. On the left, navigate to files and upload the \"kaggle.json\" file. Once that is done, you can continue with running the cell below that will automatically download the data for you.\n",
    "A more detailed description with pictures can be found [here](https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/)\n",
    "\n",
    "Notably you will first need to accept the Challenge Rules in order to download the data."
   ],
   "metadata": {
    "id": "Sqg4z4BntEgz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install -U scikit-learn\n",
    "!pip install -U tqdm\n",
    "!pip install -U torch torchvision\n",
    "!pip install -U numpy\n",
    "!pip install -U matplotlib \n",
    "!pip install -U Pillow\n",
    "!pip install -U pandas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install kaggle\n",
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "DATADIR = \"./data/galaxy_zoo\"\n",
    "\n",
    "file_x = \"images_training_rev1.zip\"\n",
    "file_y = \"training_solutions_rev1.zip\"\n",
    "competition = \"galaxy-zoo-the-galaxy-challenge\"\n",
    "\n",
    "!kaggle competitions download -p ./ -f $file_x $competition\n",
    "!kaggle competitions download -p ./ -f $file_y $competition\n",
    "!mkdir -p $DATADIR\n",
    "!unzip -qq ./$file_x -d $DATADIR\n",
    "!unzip -qq ./$file_y -d $DATADIR"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_CYA8Zh3sjNb",
    "outputId": "994d94cc-f661-4c70-ea0d-b8acd0712733"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# the data can now be found in \n",
    "images_folder = DATADIR + \"/images_training_rev1/\"\n",
    "labels_file = DATADIR + \"/training_solutions_rev1.csv\""
   ],
   "outputs": [],
   "metadata": {
    "id": "8B3_FfSMulTH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data consists of 424x424 px RGB images together with a vector of 37 labels as float values. The labels were obtained asking citizen scientists a number of questions in a hierarchical order, the labels are obtained as the amount of people giving the same answer. More details can be found at [www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge/](https://www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge/)"
   ],
   "metadata": {
    "id": "hVkyx_o0v1-d"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataloader"
   ],
   "metadata": {
    "id": "oL22f8vn8zKV"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn import Module, Sequential, Linear, ReLU, Flatten, MSELoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torchvision.transforms import Compose, CenterCrop, ToTensor, Resize\n",
    "import torchvision.models as models\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "metadata": {
    "id": "wKadgvL8zA97"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since training takes a lot of time otherwise, you should use cuda. On Colab, you can do this by clicking \"Runtime\" (next to \"Tools\" in top-left) and than \"Change Runtime type\" and choose GPU."
   ],
   "metadata": {
    "id": "xLjZm_Tz7nzb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxfDGFCCx8AA",
    "outputId": "674d020a-f965-4476-e41e-aa68dbea29cc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def get_labels() -> torch.Tensor:\n",
    "    df_galaxy_labels =  read_csv(labels_file)\n",
    "    labels = df_galaxy_labels[df_galaxy_labels.columns[1:]].values\n",
    "    labels = torch.from_numpy(labels).float()\n",
    "    return labels\n",
    "\n",
    "\n",
    "class DataSet(Dataset):\n",
    "    def __init__(self):\n",
    "        self.path_images = images_folder\n",
    "        file_list = glob(self.path_images + \"*\")\n",
    "        file_list.sort()\n",
    "        df_galaxy_labels =  read_csv(labels_file)\n",
    "        labels_train = df_galaxy_labels[df_galaxy_labels.columns[1:]].values\n",
    "        labels_train = torch.from_numpy(labels_train).float()\n",
    "        labels = get_labels()\n",
    "        self.data = []\n",
    "        for file, label in zip(file_list, labels):\n",
    "            self.data.append([file, label])\n",
    "\n",
    "        self.augment = Compose([\n",
    "            CenterCrop(207),  ## galaxy is in the center of the image\n",
    "            Resize((64,) * 2),  ## reduce size to improve speed\n",
    "            ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file, label = self.data[index]\n",
    "        img = Image.open(file)\n",
    "        img = self.augment(img)\n",
    "        return img, label\n",
    "\n",
    "class MakeDataLoader:\n",
    "    def __init__(self, test_size=0.1, random_state=2):\n",
    "        self.dataset = DataSet()\n",
    "        train_idx, test_idx = train_test_split(list(range(len(self.dataset))), train_size=1-test_size, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        indices = torch.randperm(len(train_idx))\n",
    "        self.dataset_train = Subset(self.dataset, np.array(train_idx)[indices])\n",
    "        self.dataset_test = Subset(self.dataset, test_idx)\n",
    "        \n",
    "        self.collate_fn = lambda x: list(map(lambda o: o.to(device), default_collate(x)))\n",
    "\n",
    "\n",
    "    def get_data_loader_full(self, batch_size=64, shuffle=True, **kwargs) -> DataLoader:\n",
    "        return DataLoader(self.dataset, batch_size=batch_size, shuffle=shuffle, drop_last=True, collate_fn=self.collate_fn, **kwargs)\n",
    "\n",
    "    def get_data_loader_train(self, batch_size=64, **kwargs) -> DataLoader:\n",
    "        return DataLoader(self.dataset_train, batch_size=batch_size, shuffle=True, drop_last=True, collate_fn=self.collate_fn, **kwargs)\n",
    "\n",
    "    def get_data_loader_test(self, batch_size=64, **kwargs) -> DataLoader:\n",
    "        return DataLoader(self.dataset_test, batch_size=batch_size, shuffle=True, drop_last=True, collate_fn=self.collate_fn, **kwargs)\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "kLjNeOMWvyhZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Investigation\n",
    "\n",
    "Here we only show a particular example of a galaxy image together with the labels."
   ],
   "metadata": {
    "id": "W-iqDD679Db-"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "make_data_loader = MakeDataLoader()\n",
    "\n",
    "data_loader = make_data_loader.get_data_loader_full(batch_size=1)\n",
    "\n",
    "for image, label in data_loader:\n",
    "    plt.imshow(image[0].cpu().permute(1, 2, 0))\n",
    "    print(label)\n",
    "    break"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "79rknUdfyYOx",
    "outputId": "a9d7940a-5faa-4cfc-d094-cf23bcae80cf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modelling\n",
    "We make a small test using all but the last layer of the ResNet-18 architecture, provided by the torchvision package."
   ],
   "metadata": {
    "id": "KeMP4JNF9TBl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Classifier(Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=False)\n",
    "        self.conv = Sequential(\n",
    "            *(list(resnet.children())[:-1]),\n",
    "            Flatten(),\n",
    "        )\n",
    "        self.dense = Sequential(\n",
    "            Linear(512, 37),\n",
    "            ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        x = self.conv(images)\n",
    "        labels = self.dense(x)\n",
    "        return labels\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        pred = model(images)\n",
    "        loss = loss_fn(pred, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(dataloader, model, loss_fn, is_test=True, batches=1):\n",
    "    full_loss = 0\n",
    "    for batch, (images, labels) in tqdm(enumerate(dataloader), desc=\"Testing\"):\n",
    "        pred = model(images)\n",
    "        loss = loss_fn(pred, labels)\n",
    "        full_loss += loss.item()\n",
    "        if batch + 1 == batches:\n",
    "            break\n",
    "    full_loss /= batch + 1\n",
    "    print(f\"{'Test' if is_test else 'Train'} loss: {full_loss:>8f}\")\n",
    "    return full_loss    "
   ],
   "outputs": [],
   "metadata": {
    "id": "DI2-DyVrzH_o"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "\n",
    "model = Classifier().to(device)\n",
    "make_data_loader = MakeDataLoader()\n",
    "train_loader = make_data_loader.get_data_loader_train(batch_size=batch_size)\n",
    "val_loader = make_data_loader.get_data_loader_test(batch_size=batch_size)\n",
    "\n",
    "loss_fn = MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "fXayE-CZ4LRp"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epochs = 2\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    loss = test(train_loader, model, loss_fn, is_test=False)\n",
    "    train_loss.append(loss)\n",
    "    loss = test(val_loader, model, loss_fn, batches=10)\n",
    "    test_loss.append(loss)\n",
    "    print(\"\\n\")\n",
    "print(\"Done!\")"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vNI0SLeE4oN3",
    "outputId": "20d3ebfb-a7b8-419a-d20a-574467c1b915"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(np.arange(epochs), train_loss, 'b', label=\"Train\")\n",
    "plt.plot(np.arange(epochs), test_loss, 'r', label=\"Test\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.legend()"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "xzlZVWj-5Tfs",
    "outputId": "1f319c70-ff02-4fd0-a608-9b12754d4843"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "id": "kvcyRM198jou"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "GalaxyZoo_dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}