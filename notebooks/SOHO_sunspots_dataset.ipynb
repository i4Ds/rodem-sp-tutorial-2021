{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOHO MDI and Sunspotter Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration \n",
    "\n",
    "### Dataset in a Nutshell\n",
    "\n",
    "- Image data collected by SOHO/MDI\n",
    "- MDI instrument data / SMART cutouts\n",
    "- Citizen science project to label (some of) the data (around 60,000 images?): People asked to classify which of two images is more complex\n",
    "- Complexity score computed from resulting rankings\n",
    "- Dataset consists of \n",
    "    - metadata file (incl. score and image file name)\n",
    "    - image files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data\n",
    "\n",
    "Can be downloaded from XXX <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./data/MDIComplexityScores\n",
    "!curl -L 'https://dl.dropboxusercontent.com/s/le0isfa0r5c0w8z/sunspot_data.zip' > sunspot_data.zip\n",
    "!unzip -q -o sunspot_data.zip -d ./data/MDIComplexityScores\n",
    "!rm -f sunspot_data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies\n",
    "\n",
    "- on Google Colab you will need to restart your runtime after this step\n",
    "- when running this locally, make sure to first follow the setup instructions in the [README](../README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Install dependencies\n",
    "\n",
    "#- on Google Colab you will need to restart your runtime after this step\n",
    "#- when running this locally, make sure to first follow the setup instructions in the [README](../README.md)!pip install -U tqdm\n",
    "!pip install -U torch torchvision\n",
    "!pip install -U numpy\n",
    "!pip install -U matplotlib \n",
    "!pip install -U Pillow\n",
    "!pip install -U pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data location\n",
    "DATADIR = \"./data/MDIComplexityScores/data/images/\"\n",
    "METADATA_FILE = \"./data/MDIComplexityScores/data/image_metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(METADATA_FILE)\n",
    "metadata.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are only interested in the `score` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = metadata.score\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Glance at a Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplefile = metadata.filename_x[0]\n",
    "image = Image.open(DATADIR + samplefile)\n",
    "imgarray = np.asarray(image)\n",
    "\n",
    "print(image.size, image.mode)\n",
    "print(imgarray.shape)\n",
    "print(imgarray.min(), imgarray.max())\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess the images\n",
    "\n",
    "- Load image, possibly resize with a suitable ratio.\n",
    "- Average over color channels.\n",
    "- Rescale intensity scale to be between `[0,1]`\n",
    "- Rearrange to have the channels in the first dimension\n",
    "\n",
    "Data are stored in the format (image_no, x_pixel, y_pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data( image_path, ratio=1 ):\n",
    "\n",
    "    # create empty data cube\n",
    "    data = []\n",
    "\n",
    "    for file in tqdm( metadata.filename_x ):\n",
    "\n",
    "        # Load and resize image\n",
    "        image = Image.open(image_path + file)\n",
    "        new_size = (np.array( image.size ) / ratio).astype( int )\n",
    "        image = image.resize( new_size )\n",
    "\n",
    "        # compute the mean along the color channel\n",
    "        image = np.mean( image, axis=2 )\n",
    "\n",
    "        # append the image to data list\n",
    "        data.append( image )\n",
    "    \n",
    "    # stack elements of the list into a data cube\n",
    "    data = np.dstack( data )\n",
    "    \n",
    "    # permute dimensions to better format \n",
    "    data = np.transpose( data, axes=(2,0,1) )\n",
    "    \n",
    "    # make sure pixel values are between 0 and 1\n",
    "    data = data / 255\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = preprocess_data( DATADIR, ratio=4 )\n",
    "print( \"Data shape: {}\".format( data.shape ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Many Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize=(20,20) )\n",
    "n = 10\n",
    "m = 10\n",
    "for i in range(n):\n",
    "    for j in range(m):\n",
    "        plt.subplot( n, m, n*i+j+1 )\n",
    "        image = np.random.randint( data.shape[0] )\n",
    "        plt.title( \"score: {}\".format( np.round( metadata.score[image]) ) )\n",
    "        plt.imshow( data[image,:,:], cmap=\"gray\" )\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complexity score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist( score )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, score, test_size=0.20, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_train_dense = X_train.reshape( X_train.shape[0], -1 )    \n",
    "X_test_dense = X_test.reshape( X_test.shape[0], -1 )\n",
    "X_train_dense.shape, X_test_dense.shape\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "X_train_dense_split = torch.split(torch.tensor(X_train_dense).float(),batch_size)\n",
    "y_train_split = torch.split(torch.tensor(y_train.values).float(),batch_size)\n",
    "\n",
    "X_test_dense_split = torch.split(torch.tensor(X_test_dense).float(),batch_size)\n",
    "y_test_split = torch.split(torch.tensor(y_test.values).float(),batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "\n",
    "model = Sequential(\n",
    "  Linear(X_train_dense.shape[1], 500), ReLU(),\n",
    "  Linear(500, 300), ReLU(),\n",
    "  Linear(300, 1) )\n",
    "\n",
    "optim = Adam(model.parameters())\n",
    "mse = MSELoss()\n",
    "\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "\n",
    "for i in range (5): \n",
    "   ltr = 0.0\n",
    "   lte = 0.0\n",
    "   print (\"Epoch: \"+str(i))\n",
    "   for j in range(len(X_train_dense_split)):\n",
    "      model.zero_grad()\n",
    "      result = model(X_train_dense_split[j]).view(-1) \n",
    "      loss = mse(result,y_train_split[j])\n",
    "      loss.backward()\n",
    "      optim.step()\n",
    "      ltr+=loss.detach()\n",
    "   for j in range(len(X_test_dense_split)):\n",
    "      result = model(X_test_dense_split[j]).view(-1)\n",
    "      loss = mse(result,y_test_split[j])\n",
    "      lte+=loss.detach()\n",
    "   losses_train.append(ltr/len(X_train_dense_split))\n",
    "   losses_test.append(lte/len(X_test_dense_split))\n",
    "    \n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( losses_train, label='training' )\n",
    "plt.plot( losses_test, label='test' )\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([5000,20000])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model( torch.tensor(X_test_dense).float() ).detach().numpy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter( y_test_pred, y_test )\n",
    "plt.xlabel(\"predicted\")\n",
    "plt.ylabel(\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "rmse = np.sqrt( mean_squared_error( y_test, y_test_pred ) )\n",
    "r2 = r2_score( y_test, y_test_pred )\n",
    "print(\"RMSE = {}, R2 = {}\".format( rmse, r2 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch.nn import Sequential, Conv2d, Linear, Flatten, ReLU\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "\n",
    "model = Sequential(\n",
    "  Conv2d(1, 16, 3, 1, padding=1), ReLU(),\n",
    "  Conv2d(16, 16, 3, 2, padding=1), ReLU(),\n",
    "  Conv2d(16, 32, 3, 1, padding=1), ReLU(),\n",
    "  Conv2d(32, 32, 3, 2, padding=1), ReLU(),\n",
    "  Flatten(),\n",
    "  Linear(13248, 1000), \n",
    "  Linear(1000, 800), \n",
    "  Linear(800, 500), \n",
    "  Linear(500, 100), \n",
    "  Linear(100,1)\n",
    ")\n",
    "\n",
    "optim = Adam(model.parameters())\n",
    "mse = MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = torch.tensor( np.expand_dims( X_train, axis=1 )).float()\n",
    "X_test_cnn =  torch.tensor( np.expand_dims( X_test, axis=1 )).float()\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "X_train_cnn_split = torch.split(X_train_cnn,batch_size)\n",
    "X_test_cnn_split = torch.split(X_test_cnn,batch_size)\n",
    "\n",
    "\n",
    "print (X_train_cnn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "\n",
    "\n",
    "for i in range (5): \n",
    "   print (\"Epoch: \"+str(i))\n",
    "   ltr = 0.0\n",
    "   lte = 0.0\n",
    "   for j in range(len(X_train_cnn_split)):\n",
    "      model.zero_grad()\n",
    "      result = model(X_train_cnn_split[j]).view(-1) \n",
    "      loss = mse(result,y_train_split[j])\n",
    "      loss.backward()\n",
    "      optim.step()\n",
    "      ltr+=loss.detach()\n",
    "   for j in range(len(X_test_cnn_split)):\n",
    "      result = model(X_test_cnn_split[j]).view(-1)\n",
    "      loss = mse(result,y_test_split[j])\n",
    "      lte+=loss.detach()\n",
    "   losses_train.append(ltr/len(X_train_dense_split))\n",
    "   losses_test.append(lte/len(X_test_dense_split))\n",
    "    \n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( losses_train, label='training' )\n",
    "plt.plot( losses_test, label='test' )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model( X_test_cnn.float() ).detach().numpy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter( y_test_pred, y_test )\n",
    "plt.xlabel(\"predicted\")\n",
    "plt.ylabel(\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "rmse = np.sqrt( mean_squared_error( y_test, y_test_pred ) )\n",
    "r2 = r2_score( y_test, y_test_pred )\n",
    "print(\"RMSE = {}, R2 = {}\".format( rmse, r2 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
